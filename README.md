# crosslingual_contextual_embeddings
I also list the experiment tasks explored in the referred paper. 

## 2019
* [Emerging Cross-lingual Structure in Pretrained Language Models, EMNLP](https://arxiv.org/pdf/1911.01464.pdf)
* [On the Cross-lingual Transferability of Monolingual Representations](https://arxiv.org/abs/1910.11856)
  * [Parameter-Efficient Transfer Learning for NLP, ICML](http://proceedings.mlr.press/v97/houlsby19a/houlsby19a.pdf)
* [Unicoder: A Universal Language Encoder by Pre-training with Multiple Cross-lingual Tasks](https://arxiv.org/pdf/1909.00964.pdf)
* [Small and Practical BERT Models for Sequence Labeling (mini-BERT), arXiv](https://arxiv.org/pdf/1909.00100.pdf)
* [Polyglot Contextual Representations Improve Crosslingual Transfer, NAACL](https://arxiv.org/pdf/1902.09697.pdf)
  * "dependency parsing, semantic role labeling, and named entity recognition"
* [Context-Aware Cross-Lingual Mapping, NAACL](https://arxiv.org/pdf/1903.03243.pdf)
  * word translation, sentence translation retrieval
* [Cross-Lingual Alignment of Contextual Word Embeddings, with Applications to Zero-shot Dependency Parsing, NAACL](https://arxiv.org/pdf/1902.09492.pdf)
  * word translation, dependency parsing
* [Cross-lingual Language Model Pretraining, NeurIPS](https://arxiv.org/pdf/1901.07291.pdf)
  * cross-lingual classification, MT, Perplexity
* [How multilingual is Multilingual BERT?, ACL](https://arxiv.org/pdf/1906.01502.pdf)
  * NER, POS tagging
* [Multilingual Constituency Parsing with Self-Attention and Pre-Training, ACL](https://arxiv.org/pdf/1812.11760.pdf)
  * constituency parsing
* [Cross-Lingual Syntactic Transfer through Unsupervised Adaptation of Invertible Projections, ACL](https://arxiv.org/pdf/1906.02656.pdf)
  * POS-tagging, dependency parsing (though cross-lingual BERT is not the main topic of this paper)
* [75 Languages, 1 Model: Parsing Universal Dependencies Universally, arXiv](https://arxiv.org/pdf/1904.02099.pdf)
  * "part-of-speech, morphological features, lemmas, and dependency trees"
* [Beto, Bentz, Becas: The Surprising Cross-Lingual Effectiveness of BERT, arXiv](https://arxiv.org/pdf/1904.09077.pdf)
  * "NLI, document classification, NER, POS tagging, and dependency parsing"

## 2018
* [Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond](https://arxiv.org/pdf/1812.10464.pdf)
  * cross-lingual classfication, bitext mining, multilingual similarity search

# References
* Some papers are referred from
  * [BERT-related Papers repository](https://github.com/tomohideshibata/BERT-related-papers)
  * [Transfer Learning in Natural Language Processing, NAACL tutorial slides](https://docs.google.com/presentation/d/1fIhGikFPnb7G5kr58OvYC3GN4io7MznnM0aAgadvJfc/edit#slide=id.g5882add69e_5_467)
